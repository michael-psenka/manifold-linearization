# -*- coding: utf-8 -*-
"""train_vae.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qXwvOYjfsH1dRM6uDE1-BCPtRX2I-KY5
"""

import numpy as np
import torch
import torch.nn.functional as F
import torch.nn as nn
import torch.optim as optim
from typing import OrderedDict
from torch.utils import data
from torchvision import datasets, transforms

import matplotlib.pyplot as plt

import flatnet
from flatnet.modules import flatnet_nn
import copy
import tqdm
import os
from sklearn.decomposition import PCA
import gc

# helper training methods

def train(model, train_loader, optimizer, epoch, grad_clip=None):
    model.train()


    pbar = tqdm.tqdm(total=len(train_loader.dataset))
    losses = OrderedDict()
    for x in train_loader:
        x = x.cuda()
        out = model.loss(x)
        optimizer.zero_grad()
        out['loss'].backward()
        if grad_clip:
            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
        optimizer.step()

        desc = f'Epoch {epoch}'
        for k, v in out.items():
            if k not in losses:
                losses[k] = []
            losses[k].append(v.item())
            avg_loss = np.mean(losses[k][-50:])
            desc += f', {k} {avg_loss:.4f}'


        pbar.set_description(desc)
        pbar.update(x.shape[0])
    pbar.close()
    return losses


def eval_loss(model, data_loader):
    model.eval()
    total_losses = OrderedDict()
    with torch.no_grad():
        for x in data_loader:
            x = x.cuda()
            out = model.loss(x)
            for k, v in out.items():
                total_losses[k] = total_losses.get(k, 0) + v.item() * x.shape[0]

        desc = 'Test '
        for k in total_losses.keys():
            total_losses[k] /= len(data_loader.dataset)
            desc += f', {k} {total_losses[k]:.4f}'
        print(desc)
    return total_losses

# model architecture
class ConvDecoder(nn.Module):
    def __init__(self, latent_dim, output_shape):
        super().__init__()
        self.latent_dim = latent_dim
        self.output_shape = output_shape

        self.base_size = (128, output_shape[1] // 8, output_shape[2] // 8)
        self.fc = nn.Linear(latent_dim, np.prod(self.base_size))
        self.deconvs = nn.Sequential(
            nn.ReLU(),
            nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, output_shape[0], 3, padding=1),
        )

    def forward(self, z):
        out = self.fc(z)
        out = out.view(out.shape[0], *self.base_size)
        out = self.deconvs(out)
        return out


class ConvEncoder(nn.Module):
    def __init__(self, input_shape, latent_dim):
        super().__init__()
        self.input_shape = input_shape
        self.latent_dim = latent_dim
        self.convs = nn.Sequential(
            nn.Conv2d(input_shape[0], 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
        )
        conv_out_dim = input_shape[1] // 8 * input_shape[2] // 8 * 256
        self.fc = nn.Linear(conv_out_dim, 2 * latent_dim)

    def forward(self, x):
        out = self.convs(x)
        out = out.view(out.shape[0], -1)
        mu, log_std = self.fc(out).chunk(2, dim=1)
        return mu, log_std


class ConvVAE(nn.Module):
    def __init__(self, input_shape, latent_size):
        super().__init__()
        assert len(input_shape) == 3

        self.input_shape = input_shape
        self.latent_size = latent_size
        self.encoder = ConvEncoder(input_shape, latent_size)
        self.decoder = ConvDecoder(latent_size, input_shape)

    def loss(self, x):
        x = 2 * x - 1
        mu, log_std = self.encoder(x)
        z = torch.randn_like(mu) * log_std.exp() + mu
        x_recon = self.decoder(z)

        recon_loss = F.mse_loss(x, x_recon, reduction='none').view(x.shape[0], -1).sum(1).mean()
        kl_loss = -log_std - 0.5 + (torch.exp(2 * log_std) + mu ** 2) * 0.5
        kl_loss = kl_loss.sum(1).mean()

        return OrderedDict(loss= recon_loss + kl_loss, recon_loss=recon_loss,
                           kl_loss=kl_loss)

    def sample(self, n):
        with torch.no_grad():
            z = torch.randn(n, self.latent_size).cuda()
            samples = torch.clamp(self.decoder(z), -1, 1)
        return samples.cpu().permute(0, 2, 3, 1).numpy() * 0.5 + 0.5


if __name__ == '__main__':

    epochs = 10
    lr = 1e-3
    batch_size=128
    grad_clip = None

    # load cifar-10

    transform = transforms.Compose([transforms.ToTensor()])
    train_data = datasets.CIFAR10('data', train=True, download=True, transform=transform)
    test_data = datasets.CIFAR10('data', train=False, download=True, transform=transform)

    # convert CIFAR10 objects to numpy arrays
    train_data = np.array(train_data.data)
    test_data = np.array(test_data.data)

    train_data = (np.transpose(train_data, (0, 3, 1, 2)) / 255.).astype('float32')
    test_data = (np.transpose(test_data, (0, 3, 1, 2)) / 255.).astype('float32')

    model = ConvVAE((3, 32, 32), 32).cuda()
    train_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True,generator=torch.Generator(device='cuda'))
    test_loader = data.DataLoader(test_data, batch_size=batch_size)

    optimizer = optim.Adam(model.parameters(), lr=lr)

    train_losses, test_losses = OrderedDict(), OrderedDict()
    for epoch in range(epochs):
        model.train()
        train_loss = train(model, train_loader, optimizer, epoch, grad_clip)
        test_loss = eval_loss(model, test_loader)

        for k in train_loss.keys():
            if k not in train_losses:
                train_losses[k] = []
                test_losses[k] = []
            train_losses[k].extend(train_loss[k])
            test_losses[k].append(test_loss[k])

    # save the model
    os.makedirs('vae_weights', exist_ok=True)
    torch.save(model.state_dict(), os.path.join('vae_weights', 'vae_model.pth'))



    x = next(iter(test_loader))[:50].cuda()
    with torch.no_grad():
        x = 2 * x - 1
        z, _ = model.encoder(x)
        x_recon = torch.clamp(model.decoder(z), -1, 1)
    reconstructions = torch.stack((x, x_recon), dim=1).view(-1, 3, 32, 32) * 0.5 + 0.5
    reconstructions = reconstructions.permute(0, 2, 3, 1).cpu().numpy() * 255

    fig, axes = plt.subplots(5, 10, figsize=(14, 7), subplot_kw={'xticks': [], 'yticks': []})
    for i, ax in enumerate(axes.flat):
        ax.imshow(reconstructions[i].astype('uint8'))
    plt.show()


    # train_loader = data.DataLoader(train_data, batch_size=25000, shuffle=True,generator=torch.Generator(device='cuda'))
    # test_loader = data.DataLoader(test_data, batch_size=10000)

    # train_data = next(iter(train_loader))
    # test_data = next(iter(test_loader))

    # train_data = train_data.cuda()
    # mu, log_std = model.encoder(train_data)
    # breakpoint()
    # z1 = torch.ones_like(mu) * log_std.exp() + mu
    # Z = torch.cat((mu, z1), dim=1)
    # f,g=flatnet.train(Z, 150,thres_recon=1e-5)

    # torch.save(f.state_dict(), os.path.join('vae_weights', 'f.pth'))
    # torch.save(g.state_dict(), os.path.join('vae_weights', 'g.pth'))
